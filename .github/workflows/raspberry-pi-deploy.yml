name: Deploy to Raspberry Pi

on:
  workflow_run:
    workflows:
      - Backend CI
      - Infrastructure CI
    types:
      - completed
    branches:
      - main
      - develop
  # 수동 실행도 지원
  workflow_dispatch:
    inputs:
      deploy_specific_services:
        description: '특정 서비스만 배포 (쉼표로 구분)'
        required: false
        default: ''
        type: string
      force_restart:
        description: '전체 서비스 강제 재시작'
        required: false
        default: false
        type: boolean
      backup_before_deploy:
        description: '배포 전 데이터 백업'
        required: false
        default: true
        type: boolean
      skip_verification:
        description: '배포 후 검증 단계 건너뛰기'
        required: false
        default: false
        type: boolean

jobs:
  prepare_deployment:
    name: Prepare Deployment
    runs-on: ubuntu-latest
    # 수정: 수동 실행 시 항상 성공, 자동 실행 시 선행 워크플로우가 성공한 경우에만 실행
    if: ${{ github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success' }}
    outputs:
      environment: ${{ steps.set_env.outputs.environment }}
      image_tag: ${{ steps.set_env.outputs.image_tag }}
      specific_services: ${{ steps.set_env.outputs.specific_services }}
      force_restart: ${{ steps.set_env.outputs.force_restart }}
      backup_before_deploy: ${{ steps.set_env.outputs.backup_before_deploy }}
      skip_verification: ${{ steps.set_env.outputs.skip_verification }}
      platform_arch: ${{ steps.set_env.outputs.platform_arch }}
      kong_image: ${{ steps.set_env.outputs.kong_image }}
    steps:
      - id: set_env
        run: |
          BRANCH_NAME="${{ github.event.workflow_run.head_branch || github.ref_name }}"
          
          if [[ "$BRANCH_NAME" == "main" ]]; then
            echo "environment=production" >> $GITHUB_OUTPUT
            echo "image_tag=latest" >> $GITHUB_OUTPUT
          else
            echo "environment=development" >> $GITHUB_OUTPUT
            echo "image_tag=develop" >> $GITHUB_OUTPUT
          fi
          
          # 라즈베리파이 ARM64 아키텍처 설정
          echo "platform_arch=linux/arm64" >> $GITHUB_OUTPUT
          
          # Kong ARM64 호환 이미지 설정 (Kong 3.0은 ARM64 지원 안함)
          echo "kong_image=kong/kong-gateway:3.4.2.0" >> $GITHUB_OUTPUT
          
          echo "배포 브랜치: $BRANCH_NAME"
          echo "이미지 태그: $(if [[ \"$BRANCH_NAME\" == \"main\" ]]; then echo \"latest\"; else echo \"develop\"; fi)"
          echo "플랫폼 아키텍처: linux/arm64"
          echo "Kong 이미지: kong/kong-gateway:3.4.2.0 (ARM64 호환)"
          
          # 수동 실행 시 입력 파라미터 처리
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "specific_services=${{ github.event.inputs.deploy_specific_services }}" >> $GITHUB_OUTPUT
            
            # 불리언 값을 문자열로 변환하여 저장
            if [[ "${{ github.event.inputs.force_restart }}" == "true" ]]; then
              echo "force_restart=true" >> $GITHUB_OUTPUT
            else
              echo "force_restart=false" >> $GITHUB_OUTPUT
            fi
            
            if [[ "${{ github.event.inputs.backup_before_deploy }}" == "true" ]]; then
              echo "backup_before_deploy=true" >> $GITHUB_OUTPUT
            else
              echo "backup_before_deploy=false" >> $GITHUB_OUTPUT
            fi
            
            if [[ "${{ github.event.inputs.skip_verification }}" == "true" ]]; then
              echo "skip_verification=true" >> $GITHUB_OUTPUT
            else
              echo "skip_verification=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "specific_services=" >> $GITHUB_OUTPUT
            echo "force_restart=false" >> $GITHUB_OUTPUT
            echo "backup_before_deploy=true" >> $GITHUB_OUTPUT
            echo "skip_verification=false" >> $GITHUB_OUTPUT
          fi
          
          # 실행 정보 출력
          echo "배포 환경: ${{ github.event.workflow_run.head_branch || github.ref_name }}"
          echo "실행 방식: ${{ github.event_name }}"
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "수동 배포 옵션:"
            echo " - 특정 서비스: ${{ github.event.inputs.deploy_specific_services || '없음 (전체 배포)' }}"
            echo " - 강제 재시작: ${{ github.event.inputs.force_restart }}"
            echo " - 데이터 백업: ${{ github.event.inputs.backup_before_deploy }}"
            echo " - 검증 건너뛰기: ${{ github.event.inputs.skip_verification }}"
          fi

  validate_images:
    name: Validate Docker Images
    needs: prepare_deployment
    runs-on: ubuntu-latest
    outputs:
      images_available: ${{ steps.check_images.outputs.images_available }}
      missing_images: ${{ steps.check_images.outputs.missing_images }}
      build_required: ${{ steps.check_build.outputs.build_required }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Check Docker Desktop Status
        run: |
          echo "=== Docker Desktop 상태 확인 ==="
          
          # Docker 데몬 상태 확인
          if docker info >/dev/null 2>&1; then
            echo "✅ Docker Desktop이 실행 중입니다."
          else
            echo "❌ Docker Desktop이 실행되지 않았습니다."
            echo "Docker Desktop을 시작하는 중..."
            
            # 운영체제별 Docker Desktop 시작 명령어
            if [[ "$OSTYPE" == "darwin"* ]]; then
              # macOS
              open -a Docker || echo "Docker Desktop 자동 시작 실패. 수동으로 시작해주세요."
            elif [[ "$OSTYPE" == "msys" ]] || [[ "$OSTYPE" == "win32" ]]; then
              # Windows
              start "" "C:\Program Files\Docker\Docker\Docker Desktop.exe" || echo "Docker Desktop 자동 시작 실패. 수동으로 시작해주세요."
            else
              # Linux
              systemctl --user start docker-desktop || echo "Docker Desktop 자동 시작 실패. 수동으로 시작해주세요."
            fi
            
            # Docker 시작 대기
            echo "Docker Desktop 시작을 기다리는 중..."
            for i in {1..30}; do
              if docker info >/dev/null 2>&1; then
                echo "✅ Docker Desktop이 성공적으로 시작되었습니다."
                break
              fi
              echo "대기 중... ($i/30)"
              sleep 10
            done
            
            # 최종 확인
            if ! docker info >/dev/null 2>&1; then
              echo "❌ Docker Desktop 시작 실패. 수동으로 Docker Desktop을 시작한 후 다시 시도해주세요."
              exit 1
            fi
          fi
          
          # Docker Buildx 확인
          if docker buildx version >/dev/null 2>&1; then
            echo "✅ Docker Buildx 사용 가능"
          else
            echo "⚠️ Docker Buildx 사용 불가"
          fi
      
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_PAT }}
      
      - name: Check Service Build Context
        id: check_build
        run: |
          echo "=== 서비스 빌드 컨텍스트 확인 ==="
          
          # 각 서비스의 Dockerfile 존재 여부 확인
          SERVICES=("auth-service" "session-service" "user-service" "feedback-service" "report-service" "realtime-service")
          BUILD_REQUIRED=false
          
          for service in "${SERVICES[@]}"; do
            DOCKERFILE_PATH="api/${service}/Dockerfile"
            if [ -f "$DOCKERFILE_PATH" ]; then
              echo "✅ $service: Dockerfile 존재 ($DOCKERFILE_PATH)"
            else
              echo "❌ $service: Dockerfile 없음 ($DOCKERFILE_PATH)"
              BUILD_REQUIRED=true
            fi
          done
          
          # 인프라스트럭처 디렉토리 확인
          if [ -d "infrastructure" ]; then
            echo "✅ infrastructure 디렉토리 존재"
          else
            echo "❌ infrastructure 디렉토리 없음"
          fi
          
          echo "build_required=$BUILD_REQUIRED" >> $GITHUB_OUTPUT
      
      - name: Check Docker Images Availability
        id: check_images
        run: |
          REPO_OWNER=$(echo "${{ github.repository_owner }}" | tr "[:upper:]" "[:lower:]")
          IMAGE_TAG="${{ needs.prepare_deployment.outputs.image_tag }}"
          
          # 확인할 서비스 목록
          SERVICES=("auth-service" "session-service" "user-service" "feedback-service" "report-service" "realtime-service")
          MISSING_IMAGES=()
          AVAILABLE_IMAGES=()
          
          echo "=== Docker 이미지 존재 여부 확인 ==="
          echo "Repository Owner: $REPO_OWNER"
          echo "Image Tag: $IMAGE_TAG"
          echo "Platform: ${{ needs.prepare_deployment.outputs.platform_arch }}"
          
          for service in "${SERVICES[@]}"; do
            IMAGE_NAME="ghcr.io/${REPO_OWNER}/haptitalk-${service}:${IMAGE_TAG}"
            echo "확인 중: $IMAGE_NAME"
            
            # 이미지 매니페스트 확인 (ARM64 지원 여부 포함)
            if docker manifest inspect "$IMAGE_NAME" >/dev/null 2>&1; then
              # ARM64 아키텍처 지원 여부 확인
              if docker manifest inspect "$IMAGE_NAME" | jq -r '.manifests[]?.platform.architecture' | grep -q "arm64"; then
                echo "✅ $service: ARM64 이미지 사용 가능"
                AVAILABLE_IMAGES+=("$service")
              else
                echo "⚠️ $service: 이미지는 존재하지만 ARM64 지원 안함"
                MISSING_IMAGES+=("$service")
              fi
            else
              echo "❌ $service: 이미지 없음"
              MISSING_IMAGES+=("$service")
            fi
          done
          
          # Kong 이미지 ARM64 호환성 확인
          KONG_IMAGE="${{ needs.prepare_deployment.outputs.kong_image }}"
          echo "Kong 이미지 확인: $KONG_IMAGE"
          if docker manifest inspect "$KONG_IMAGE" | jq -r '.manifests[]?.platform.architecture' | grep -q "arm64"; then
            echo "✅ Kong: ARM64 호환 이미지 사용 가능"
          else
            echo "❌ Kong: ARM64 호환 이미지 없음"
          fi
          
          # 결과 출력
          echo "사용 가능한 이미지: ${AVAILABLE_IMAGES[*]}"
          echo "누락된 이미지: ${MISSING_IMAGES[*]}"
          
          # GitHub Actions 출력 설정
          if [ ${#MISSING_IMAGES[@]} -eq 0 ]; then
            echo "images_available=true" >> $GITHUB_OUTPUT
            echo "missing_images=" >> $GITHUB_OUTPUT
          else
            echo "images_available=false" >> $GITHUB_OUTPUT
            echo "missing_images=${MISSING_IMAGES[*]}" >> $GITHUB_OUTPUT
          fi
      
      - name: Handle Missing Images
        if: steps.check_images.outputs.images_available == 'false'
        run: |
          echo "⚠️ 일부 이미지가 누락되었습니다: ${{ steps.check_images.outputs.missing_images }}"
          echo "누락된 이미지가 있어도 배포를 계속 진행합니다."
          echo "누락된 서비스는 기존 이미지를 사용하거나 건너뛸 수 있습니다."

  setup_ssh_connection:
    name: Setup SSH Connection
    needs: prepare_deployment
    runs-on: ubuntu-latest
    steps:
      - name: Install cloudflared and Set up SSH
        run: |
          # cloudflared 설치
          curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared
          chmod +x cloudflared
          sudo mv cloudflared /usr/local/bin
          cloudflared version
          
          # SSH 디렉토리 확인 및 생성
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          
          # 시크릿에 저장된 SSH 키 사용
          echo "${{ secrets.RASPBERRY_PI_SSH_KEY }}" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          
          # cloudflared로 로컬 포트 2222를 라즈베리파이 SSH 포트로 포워딩
          echo "Cloudflared TCP 포트 포워딩 설정 중..."
          nohup cloudflared access tcp --hostname pi.eumgyeol.com --url 127.0.0.1:2222 --loglevel debug > cloudflared.log 2>&1 &
          CLOUDFLARED_PID=$!
          echo "Cloudflared PID: $CLOUDFLARED_PID"
          
          # 설정 확인을 위해 대기
          sleep 10
          
          # cloudflared 상태 확인
          if ps -p $CLOUDFLARED_PID > /dev/null; then
            echo "cloudflared 프로세스가 실행 중입니다."
            
            # cloudflared 로그 확인
            echo "cloudflared 로그:"
            cat cloudflared.log || echo "로그 파일이 없습니다."
            
            # SSH 설정 - 로컬 포트로 연결
            {
              echo "Host raspberry-pi"
              echo "  HostName localhost"
              echo "  Port 2222"
              echo "  User ${{ secrets.RASPBERRY_PI_USER }}"
              echo "  IdentityFile ~/.ssh/id_ed25519"
              echo "  StrictHostKeyChecking no"
              echo "  UserKnownHostsFile /dev/null"
              echo "  LogLevel DEBUG3"
              echo "  ConnectTimeout 30"
              echo "  ServerAliveInterval 60"
              echo "  ServerAliveCountMax 10"
            } > ~/.ssh/config
            chmod 600 ~/.ssh/config
          else
            echo "cloudflared 프로세스 시작 실패"
            cat cloudflared.log || echo "로그 파일이 없습니다"
            
            # 재시도
            echo "cloudflared 재시작을 시도합니다..."
            pkill cloudflared || echo "기존 프로세스가 없습니다"
            sleep 2
            nohup cloudflared access tcp --hostname pi.eumgyeol.com --url 127.0.0.1:2222 --loglevel debug > cloudflared_retry.log 2>&1 &
            CLOUDFLARED_PID=$!
            sleep 10
            
            if ps -p $CLOUDFLARED_PID > /dev/null; then
              echo "cloudflared 재시작 성공"
              {
                echo "Host raspberry-pi"
                echo "  HostName localhost"
                echo "  Port 2222"
                echo "  User ${{ secrets.RASPBERRY_PI_USER }}"
                echo "  IdentityFile ~/.ssh/id_ed25519"
                echo "  StrictHostKeyChecking no"
                echo "  UserKnownHostsFile /dev/null"
                echo "  LogLevel DEBUG3"
                echo "  ConnectTimeout 30"
                echo "  ServerAliveInterval 60"
                echo "  ServerAliveCountMax 10"
              } > ~/.ssh/config
              chmod 600 ~/.ssh/config
            else
              echo "cloudflared 재시작 실패"
              cat cloudflared_retry.log || echo "재시도 로그 파일이 없습니다"
              exit 1
            fi
          fi
      
      - name: Test SSH Connection
        id: ssh_test
        run: |
          echo "SSH 연결 테스트 중..."
          
          # SSH 키 기반 인증으로 연결 시도
          if ssh -o ConnectTimeout=20 raspberry-pi 'echo "Connection successful" && uptime'; then
            echo "ssh_connected=true" >> $GITHUB_OUTPUT
          else
            echo "ssh_connected=false" >> $GITHUB_OUTPUT
            echo "연결 실패. 자세한 로그:"
            ssh -vvv raspberry-pi 'echo test' || true
            cat cloudflared.log || echo "cloudflared 로그 파일이 없습니다."
            
            # 재시도
            echo "SSH 연결 재시도..."
            pkill cloudflared || echo "cloudflared 프로세스가 없습니다"
            sleep 2
            
            # cloudflared 재설치
            curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared
            chmod +x cloudflared
            sudo mv cloudflared /usr/local/bin
            
            nohup cloudflared access tcp --hostname pi.eumgyeol.com --url 127.0.0.1:2222 --loglevel debug > cloudflared_retry2.log 2>&1 &
            sleep 10
            
            if ssh -o ConnectTimeout=20 raspberry-pi 'echo "Connection successful on retry" && uptime'; then
              echo "ssh_connected=true" >> $GITHUB_OUTPUT
            else
              echo "SSH 재시도 실패. 워크플로우를 중단합니다."
              cat cloudflared_retry2.log || echo "재시도 로그 파일이 없습니다"
              exit 1
            fi
          fi

  check_raspberry_pi:
    name: Check Raspberry Pi Health
    needs: [prepare_deployment, setup_ssh_connection, validate_images]
    runs-on: ubuntu-latest
    steps:
      - name: Setup SSH Connection Again
        run: |
          # 이전 cloudflared 프로세스 종료
          pkill cloudflared || echo "실행 중인 cloudflared 프로세스가 없습니다"
          
          # cloudflared 설치
          echo "cloudflared 설치 중..."
          curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared
          chmod +x cloudflared
          sudo mv cloudflared /usr/local/bin
          cloudflared version
          
          # SSH 디렉토리 확인 및 생성
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          
          # SSH 키 확인 (이미 있으면 다시 생성하지 않음)
          if [ ! -f ~/.ssh/id_ed25519 ]; then
            echo "${{ secrets.RASPBERRY_PI_SSH_KEY }}" > ~/.ssh/id_ed25519
            chmod 600 ~/.ssh/id_ed25519
          fi
          
          # 새 cloudflared TCP 터널 설정
          echo "Cloudflared TCP 포트 포워딩 설정 중..."
          nohup cloudflared access tcp --hostname pi.eumgyeol.com --url 127.0.0.1:2222 --loglevel debug > cloudflared_health.log 2>&1 &
          CLOUDFLARED_PID=$!
          echo "Cloudflared PID: $CLOUDFLARED_PID"
          
          # 설정 확인을 위해 대기
          sleep 10
          
          # cloudflared 상태 확인
          if ps -p $CLOUDFLARED_PID > /dev/null; then
            echo "cloudflared 프로세스가 실행 중입니다."
            
            # cloudflared 로그 확인
            echo "cloudflared 로그:"
            cat cloudflared_health.log || echo "로그 파일이 없습니다."
            
            # SSH 설정 - 로컬 포트로 연결
            {
              echo "Host raspberry-pi"
              echo "  HostName localhost"
              echo "  Port 2222"
              echo "  User ${{ secrets.RASPBERRY_PI_USER }}"
              echo "  IdentityFile ~/.ssh/id_ed25519"
              echo "  StrictHostKeyChecking no"
              echo "  UserKnownHostsFile /dev/null"
              echo "  LogLevel DEBUG3"
              echo "  ConnectTimeout 30"
              echo "  ServerAliveInterval 60"
              echo "  ServerAliveCountMax 10"
            } > ~/.ssh/config
            chmod 600 ~/.ssh/config
          else
            echo "cloudflared 프로세스 시작 실패"
            cat cloudflared_health.log || echo "로그 파일이 없습니다"
            exit 1
          fi
          
      - name: Test SSH Connection
        run: |
          echo "SSH 연결 테스트 중..."
          
          # SSH 키 기반 인증으로 연결 시도 
          if ssh -o ConnectTimeout=20 raspberry-pi 'echo "Connection successful" && uptime'; then
            echo "SSH 연결 성공"
          else
            echo "SSH 연결 실패. 자세한 로그:"
            ssh -vvv raspberry-pi 'echo test' || true
            cat cloudflared_health.log || echo "cloudflared 로그 파일이 없습니다."
            
            # 재시도
            echo "SSH 연결 재시도..."
            pkill cloudflared || echo "cloudflared 프로세스가 없습니다"
            sleep 2
            
            nohup cloudflared access tcp --hostname pi.eumgyeol.com --url 127.0.0.1:2222 --loglevel debug > cloudflared_retry_health.log 2>&1 &
            sleep 10
            
            if ssh -o ConnectTimeout=20 raspberry-pi 'echo "Connection successful on retry" && uptime'; then
              echo "SSH 재연결 성공"
            else
              echo "SSH 재시도 실패. 워크플로우를 중단합니다."
              cat cloudflared_retry_health.log || echo "재시도 로그 파일이 없습니다"
              exit 1
            fi
          fi
          
      - name: Setup Docker Authentication on Raspberry Pi
        run: |
          # GitHub Container Registry 인증 설정
          echo "GitHub Container Registry 인증 설정 중..."
          
          # read:packages 권한이 있는 PAT 토큰 사용
          echo "${{ secrets.GHCR_PAT }}" | ssh raspberry-pi "cat > ~/.github_token"
          
          # 라즈베리파이에서 Docker 로그인 실행
          ssh raspberry-pi '
            echo "GitHub Container Registry 인증 설정 중..."
            cat ~/.github_token | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
            rm ~/.github_token  # 보안을 위해 토큰 파일 삭제
          '
      
      - name: Check Disk Space
        id: disk_check
        run: |
          # 디스크 공간 확인
          DISK_INFO=$(ssh raspberry-pi 'df -h | grep -E "/$"')
          
          # 디스크 사용량 추출 (% 제거)
          DISK_USAGE=$(echo "$DISK_INFO" | awk '{print $5}' | sed 's/%//')
          echo "disk_usage=$DISK_USAGE" >> $GITHUB_OUTPUT
          
          # 사용 가능한 공간 확인 (MB 단위)
          AVAILABLE_SPACE=$(ssh raspberry-pi 'df -m | grep -E "/$" | awk "{print \$4}"')
          echo "available_space=${AVAILABLE_SPACE}MB" >> $GITHUB_OUTPUT
          
          # 최소 필요 공간: 500MB
          if [ "$AVAILABLE_SPACE" -lt 500 ]; then
            echo "disk_warning=true" >> $GITHUB_OUTPUT
          else
            echo "disk_warning=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Check RAM
        id: ram_check
        run: |
          # 메모리 정보 확인
          RAM_INFO=$(ssh raspberry-pi 'free -m | grep "Mem:"')
          
          # 사용 가능한 메모리 추출 (MB)
          AVAILABLE_RAM=$(echo "$RAM_INFO" | awk '{print $7}')
          echo "available_ram=${AVAILABLE_RAM}MB" >> $GITHUB_OUTPUT
          
          # 최소 필요 메모리: 200MB
          if [ "$AVAILABLE_RAM" -lt 200 ]; then
            echo "ram_warning=true" >> $GITHUB_OUTPUT
          else
            echo "ram_warning=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Display Resource Info
        run: |
          echo "디스크 사용량: ${{ steps.disk_check.outputs.disk_usage }}%"
          echo "사용 가능한 디스크 공간: ${{ steps.disk_check.outputs.available_space }}"
          echo "사용 가능한 메모리: ${{ steps.ram_check.outputs.available_ram }}"
      
      - name: Clean Up if Necessary
        if: steps.disk_check.outputs.disk_warning == 'true'
        run: |
          echo "디스크 공간 부족, 정리 작업 수행 중..."
          ssh raspberry-pi '
            # 미사용 도커 리소스 정리
            docker system prune -af --volumes
            
            # 로그 파일 정리
            find /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk -name "*.log" -type f -exec rm -f {} \;
            
            # 임시 파일 삭제
            sudo find /tmp -type f -atime +5 -delete
          '
          
          # 정리 후 디스크 공간 다시 확인
          DISK_USAGE_AFTER=$(ssh raspberry-pi 'df -h | grep -E "/$" | awk "{print \$5}" | sed "s/%//"')
          
          echo "정리 후 디스크 사용량: ${DISK_USAGE_AFTER}%"

  backup_data:
    name: Backup Data
    needs: [prepare_deployment, setup_ssh_connection, check_raspberry_pi, validate_images]
    runs-on: ubuntu-latest
    if: needs.prepare_deployment.outputs.backup_before_deploy == 'true'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup SSH Connection Again
        run: |
          # 이전 cloudflared 프로세스 종료
          pkill cloudflared || echo "실행 중인 cloudflared 프로세스가 없습니다"
          
          # cloudflared 설치
          echo "cloudflared 설치 중..."
          curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared
          chmod +x cloudflared
          sudo mv cloudflared /usr/local/bin
          cloudflared version
          
          # SSH 디렉토리 확인 및 생성
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          
          # SSH 키 확인 (이미 있으면 다시 생성하지 않음)
          if [ ! -f ~/.ssh/id_ed25519 ]; then
            echo "${{ secrets.RASPBERRY_PI_SSH_KEY }}" > ~/.ssh/id_ed25519
            chmod 600 ~/.ssh/id_ed25519
          fi
          
          # 새 cloudflared TCP 터널 설정
          echo "Cloudflared TCP 포트 포워딩 설정 중..."
          nohup cloudflared access tcp --hostname pi.eumgyeol.com --url 127.0.0.1:2222 --loglevel debug > cloudflared_backup.log 2>&1 &
          CLOUDFLARED_PID=$!
          echo "Cloudflared PID: $CLOUDFLARED_PID"
          
          # 설정 확인을 위해 대기
          sleep 10
          
          # cloudflared 상태 확인
          if ps -p $CLOUDFLARED_PID > /dev/null; then
            echo "cloudflared 프로세스가 실행 중입니다."
            
            # cloudflared 로그 확인
            echo "cloudflared 로그:"
            cat cloudflared_backup.log || echo "로그 파일이 없습니다."
            
            # SSH 설정 - 로컬 포트로 연결
            {
              echo "Host raspberry-pi"
              echo "  HostName localhost"
              echo "  Port 2222"
              echo "  User ${{ secrets.RASPBERRY_PI_USER }}"
              echo "  IdentityFile ~/.ssh/id_ed25519"
              echo "  StrictHostKeyChecking no"
              echo "  UserKnownHostsFile /dev/null"
              echo "  LogLevel DEBUG3"
              echo "  ConnectTimeout 30"
              echo "  ServerAliveInterval 60"
              echo "  ServerAliveCountMax 10"
            } > ~/.ssh/config
            chmod 600 ~/.ssh/config
          else
            echo "cloudflared 프로세스 시작 실패"
            cat cloudflared_backup.log || echo "로그 파일이 없습니다"
            exit 1
          fi
          
      - name: Test SSH Connection
        run: |
          echo "SSH 연결 테스트 중..."
          
          # SSH 키 기반 인증으로 연결 시도 
          if ssh -o ConnectTimeout=20 raspberry-pi 'echo "Connection successful" && uptime'; then
            echo "SSH 연결 성공"
          else
            echo "SSH 연결 실패. 자세한 로그:"
            ssh -vvv raspberry-pi 'echo test' || true
            cat cloudflared_backup.log || echo "cloudflared 로그 파일이 없습니다."
            
            # 재시도
            echo "SSH 연결 재시도..."
            pkill cloudflared || echo "cloudflared 프로세스가 없습니다"
            sleep 2
            
            nohup cloudflared access tcp --hostname pi.eumgyeol.com --url 127.0.0.1:2222 --loglevel debug > cloudflared_retry_backup.log 2>&1 &
            sleep 10
            
            if ssh -o ConnectTimeout=20 raspberry-pi 'echo "Connection successful on retry" && uptime'; then
              echo "SSH 재연결 성공"
            else
              echo "SSH 재시도 실패. 워크플로우를 중단합니다."
              cat cloudflared_retry_backup.log || echo "재시도 로그 파일이 없습니다"
              exit 1
            fi
          fi
      
      - name: Setup Docker Authentication on Raspberry Pi
        run: |
          # GitHub Container Registry 인증 설정
          echo "GitHub Container Registry 인증 설정 중..."
          
          # read:packages 권한이 있는 PAT 토큰 사용
          echo "${{ secrets.GHCR_PAT }}" | ssh raspberry-pi "cat > ~/.github_token"
          
          # 라즈베리파이에서 Docker 로그인 실행
          ssh raspberry-pi '
            echo "GitHub Container Registry 인증 설정 중..."
            cat ~/.github_token | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
            rm ~/.github_token  # 보안을 위해 토큰 파일 삭제
          '
      
      - name: Transfer Docker Compose Files
        run: |
          # 기존 docker-compose.yml 확인 및 수정
          echo "Docker Compose 파일 준비 중..."
          
          # 레포지토리에서 docker-compose.yml 파일 사용 (이미 체크아웃됨)
          if [ -f "docker-compose.yml" ]; then
            echo "기존 docker-compose.yml 파일을 사용합니다."
          else
            echo "docker-compose.yml 파일이 없습니다. 기본 파일을 생성합니다."
            # 기본 docker-compose.yml 생성 (간단한 버전)
            cat > docker-compose.yml << 'EOF'
          version: "3.8"
          services:
            postgres:
              image: postgres:14-alpine
              restart: always
              environment:
                POSTGRES_USER: ${POSTGRES_USER}
                POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
                POSTGRES_DB: ${POSTGRES_DB}
              ports:
                - "${POSTGRES_PORT:-5432}:5432"
            redis:
              image: redis:7-alpine
              restart: always
              command: redis-server --requirepass ${REDIS_PASSWORD}
              ports:
                - "${REDIS_PORT:-6379}:6379"
          volumes:
            postgres_data:
            redis_data:
          EOF
          fi
          
          # ARM64 호환 docker-compose.prod.yml 파일 생성 (별도 파일로)
          echo "ARM64 호환 docker-compose.prod.yml 생성 중..."
          
          # 라즈베리파이에 파일 전송
          scp -o StrictHostKeyChecking=no docker-compose.yml raspberry-pi:/home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/
          
          # 기존 프로덕션 파일이 있으면 사용, 없으면 개발용을 복사
          if [ -f "docker-compose.prod.yml" ]; then
            echo "기존 docker-compose.prod.yml 파일을 사용합니다 (ARM64 호환 완료)."
            scp -o StrictHostKeyChecking=no docker-compose.prod.yml raspberry-pi:/home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/
          else
            echo "docker-compose.prod.yml이 없어서 기본 파일을 복사합니다."
            cp docker-compose.yml docker-compose.prod.yml
            scp -o StrictHostKeyChecking=no docker-compose.prod.yml raspberry-pi:/home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/
          fi
          
          scp -o StrictHostKeyChecking=no docker-compose.prod.yml raspberry-pi:/home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/
          
          # 필요한 디렉토리 구조 생성
          ssh raspberry-pi << 'REMOTE_SCRIPT'
            mkdir -p /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/database/postgres/init
            mkdir -p /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/database/mongodb/init
            mkdir -p /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/database/redis/init
            mkdir -p /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/api-gateway
            mkdir -p /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/static-web/html
          REMOTE_SCRIPT
          
          # Kong 설정 파일 전송 (필요시)
          if [ -f "infrastructure/api-gateway/kong.yml" ]; then
            scp -o StrictHostKeyChecking=no infrastructure/api-gateway/kong.yml raspberry-pi:/home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/api-gateway/
          else
            # 기본 Kong 설정 파일 생성
            mkdir -p infrastructure/api-gateway
            cat > infrastructure/api-gateway/kong.yml << 'EOF'
          _format_version: "2.1"
          _transform: true
          
          services:
            - name: default-service
              url: http://static-web
              routes:
                - name: default-route
                  paths:
                    - /
          EOF
            scp -o StrictHostKeyChecking=no infrastructure/api-gateway/kong.yml raspberry-pi:/home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/api-gateway/
          fi
          
          # .env 파일을 단계별로 생성
          echo "POSTGRES_USER=${{ secrets.POSTGRES_USER }}" > .env
          echo "POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}" >> .env
          echo "POSTGRES_DB=${{ secrets.POSTGRES_DB }}" >> .env
          echo "POSTGRES_VOLUME_NAME=postgres_data" >> .env
          echo "POSTGRES_PORT=5432" >> .env
          echo "" >> .env
          echo "MONGO_USER=${{ secrets.MONGO_USER }}" >> .env
          echo "MONGO_PASSWORD=${{ secrets.MONGO_PASSWORD }}" >> .env
          echo "MONGO_DB=${{ secrets.MONGO_DB }}" >> .env
          echo "MONGODB_VOLUME_NAME=mongodb_data" >> .env
          echo "MONGO_PORT=27017" >> .env
          echo "" >> .env
          echo "REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD }}" >> .env
          echo "REDIS_VOLUME_NAME=redis_data" >> .env
          echo "REDIS_PORT=6379" >> .env
          echo "" >> .env
          echo "ZOOKEEPER_PORT=2181" >> .env
          echo "KAFKA_PORT=9092" >> .env
          echo "KAFKA_UI_PORT=8080" >> .env
          echo "" >> .env
          echo "KONG_PROXY_PORT=8000" >> .env
          echo "KONG_HTTPS_PORT=8443" >> .env
          echo "KONG_ADMIN_PORT=8001" >> .env
          echo "KONG_VOLUME_NAME=kong_data" >> .env
          echo "" >> .env
          echo "JWT_ACCESS_SECRET=${{ secrets.JWT_ACCESS_SECRET }}" >> .env
          echo "JWT_REFRESH_SECRET=${{ secrets.JWT_REFRESH_SECRET }}" >> .env
          echo "JWT_SESSION_SECRET=${{ secrets.JWT_SESSION_SECRET }}" >> .env
          echo "JWT_ACCESS_EXPIRES_IN=15m" >> .env
          echo "JWT_REFRESH_EXPIRES_IN=7d" >> .env
          echo "JWT_SESSION_EXPIRES_IN=30d" >> .env
          echo "" >> .env
          echo "KAFKA_TOPIC_SESSION_EVENTS=session-events" >> .env
          echo "KAFKA_TOPIC_ANALYSIS_RESULTS=analysis-results" >> .env
          echo "KAFKA_TOPIC_FEEDBACK_COMMANDS=feedback-commands" >> .env
          echo "KAFKA_TOPIC_USER_ACTIVITY=user-activity" >> .env
          echo "" >> .env
          echo "AUTH_SERVICE_PORT=3000" >> .env
          echo "REALTIME_SERVICE_PORT=3001" >> .env
          echo "SESSION_SERVICE_PORT=3002" >> .env
          echo "FEEDBACK_SERVICE_PORT=3003" >> .env
          echo "USER_SERVICE_PORT=3004" >> .env
          echo "REPORT_SERVICE_PORT=3005" >> .env
          echo "" >> .env
          echo "LOG_LEVEL=info" >> .env
          echo "FRONTEND_URL=http://${{ secrets.RASPBERRY_PI_IP }}:8080" >> .env
          echo "EMAIL_FROM=no-reply@haptitalk.com" >> .env
          echo "" >> .env
          echo "DEPLOY_VERSION=$(date +%Y%m%d%H%M%S)" >> .env
          echo "DEPLOY_ENVIRONMENT=${{ needs.prepare_deployment.outputs.environment }}" >> .env
          echo "" >> .env
          echo "# 모니터링 시스템 설정" >> .env
          echo "ELASTICSEARCH_PORT=9200" >> .env
          echo "KIBANA_PORT=5601" >> .env
          echo "LOGSTASH_BEATS_PORT=5044" >> .env
          echo "LOGSTASH_TCP_PORT=5000" >> .env
          echo "LOGSTASH_API_PORT=9600" >> .env
          echo "JAEGER_UI_PORT=16686" >> .env
          echo "JAEGER_COLLECTOR_GRPC_PORT=14250" >> .env
          echo "JAEGER_COLLECTOR_HTTP_PORT=14268" >> .env
          echo "JAEGER_OTLP_PORT=4318" >> .env
          echo "JAEGER_OTLP_GRPC_PORT=4317" >> .env
          echo "OTEL_COLLECTOR_PORT=4317" >> .env
          echo "OTEL_COLLECTOR_HTTP_PORT=4318" >> .env
          echo "OTEL_COLLECTOR_PROM_PORT=8889" >> .env
          echo "OTEL_COLLECTOR_ZPAGES_PORT=55679" >> .env
          echo "PROMETHEUS_PORT=9090" >> .env
          echo "GRAFANA_PORT=3000" >> .env
          echo "NODE_EXPORTER_PORT=9100" >> .env
          echo "" >> .env
          echo "# Exporters 포트 설정" >> .env
          echo "MONGODB_EXPORTER_PORT=9216" >> .env
          echo "POSTGRES_EXPORTER_PORT=9187" >> .env
          echo "REDIS_EXPORTER_PORT=9121" >> .env
          echo "ELASTICSEARCH_EXPORTER_PORT=9114" >> .env
          echo "LOGSTASH_EXPORTER_PORT=9304" >> .env
          echo "KONG_BLACKBOX_EXPORTER_PORT=9701" >> .env
          echo "KIBANA_BLACKBOX_EXPORTER_PORT=9702" >> .env
          echo "MONGODB_BLACKBOX_EXPORTER_PORT=9703" >> .env
          echo "" >> .env
          echo "# ELK 스택 인증 설정" >> .env
          echo "ELASTIC_USERNAME=elastic" >> .env
          echo "ELASTIC_PASSWORD=changeme" >> .env
          echo "" >> .env
          echo "# Grafana 설정" >> .env
          echo "GRAFANA_ADMIN_USER=admin" >> .env
          echo "GRAFANA_ADMIN_PASSWORD=admin" >> .env
          echo "" >> .env
          echo "# 볼륨 설정" >> .env
          echo "ELASTICSEARCH_VOLUME_NAME=elasticsearch_data" >> .env
          echo "PROMETHEUS_VOLUME_NAME=prometheus_data" >> .env
          echo "GRAFANA_VOLUME_NAME=grafana_data" >> .env
          echo "JAEGER_VOLUME_NAME=jaeger_data" >> .env
          echo "LOGSTASH_DATA_VOLUME_NAME=logstash_data" >> .env
          
          scp -o StrictHostKeyChecking=no .env raspberry-pi:/home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/
          
          # 인프라스트럭처 디렉토리 전송 (존재하는 경우에만)
          if [ -d "infrastructure" ]; then
            scp -o StrictHostKeyChecking=no -r infrastructure raspberry-pi:/home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/
          else
            echo "infrastructure 디렉토리가 존재하지 않습니다. 원격에서 생성합니다."
            # 원격에서 필요한 디렉토리 구조 생성
            ssh raspberry-pi << 'REMOTE_SCRIPT2'
              mkdir -p /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/database/postgres/init
              mkdir -p /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/database/mongodb/init
              mkdir -p /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/database/redis/init
              mkdir -p /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/api-gateway
              mkdir -p /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/infrastructure/static-web/html
          REMOTE_SCRIPT2
          fi
          
          # 배포 스크립트 생성 및 전송
          cat > deploy.sh << 'DEPLOY_EOF'
          #!/bin/bash
          set -e
          
          # 배포 로그 시작
          DEPLOY_LOG="/home/${USER}/haptitalk/logs/deploy_$(date +%Y%m%d_%H%M%S).log"
          mkdir -p /home/${USER}/haptitalk/logs
          
          echo "===== 배포 시작: $(date) =====" | tee -a $DEPLOY_LOG
          cd /home/${USER}/haptitalk
          
          # 디렉토리 구조 확인
          mkdir -p infrastructure/database/postgres/init
          mkdir -p infrastructure/database/mongodb/init
          mkdir -p infrastructure/database/redis/init
          mkdir -p infrastructure/api-gateway
          mkdir -p infrastructure/messaging/kafka/init
          mkdir -p infrastructure/static-web/html
          mkdir -p infrastructure/monitoring
          
          # 환경 변수 검증
          echo "환경 변수 검증 중..." | tee -a $DEPLOY_LOG
          if [ -z "$POSTGRES_PASSWORD" ] || [ -z "$REDIS_PASSWORD" ] || [ -z "$JWT_ACCESS_SECRET" ]; then
            echo "오류: 필수 환경 변수가 설정되지 않았습니다." | tee -a $DEPLOY_LOG
            exit 1
          fi
          
          # Docker 네트워크 생성
          docker network create haptitalk_network 2>/dev/null || echo "네트워크가 이미 존재합니다."
          
          # 이미지 가져오기 (ARM64 플랫폼 지정)
          echo "ARM64 도커 이미지 업데이트 중..." | tee -a $DEPLOY_LOG
          docker-compose -f docker-compose.prod.yml pull --platform linux/arm64 || echo "일부 이미지를 가져오지 못했습니다. 계속 진행합니다." | tee -a $DEPLOY_LOG
          
          # 기존 컨테이너 상태 저장 (롤백용)
          echo "현재 컨테이너 상태 백업 중..." | tee -a $DEPLOY_LOG
          docker-compose -f docker-compose.prod.yml ps > /home/${USER}/haptitalk/container_state_before_deploy.txt || true
          
          # 특정 서비스만 재시작 여부 확인
          SPECIFIC_SERVICES="$1"
          FORCE_RESTART="$2"
          MISSING_IMAGES="$3"
          
          # 실제 배포 시작
          echo "배포 시작..." | tee -a $DEPLOY_LOG
          
          if [ "$FORCE_RESTART" == "true" ]; then
            echo "강제 재시작 모드: 모든 컨테이너를 중지하고 재시작합니다." | tee -a $DEPLOY_LOG
            docker-compose -f docker-compose.prod.yml down --remove-orphans
            docker-compose -f docker-compose.prod.yml up -d
          elif [ -n "$SPECIFIC_SERVICES" ]; then
            echo "특정 서비스만 재시작: $SPECIFIC_SERVICES" | tee -a $DEPLOY_LOG
            IFS=',' read -ra SERVICES <<< "$SPECIFIC_SERVICES"
            for service in "${SERVICES[@]}"; do
              echo "서비스 재시작: $service" | tee -a $DEPLOY_LOG
              # 서비스 존재 여부 확인 후 재시작
              if grep -q "$service:" docker-compose.prod.yml; then
                docker-compose -f docker-compose.prod.yml stop $service || true
                docker-compose -f docker-compose.prod.yml rm -f $service || true
                docker-compose -f docker-compose.prod.yml up -d $service
              else
                echo "경고: $service 서비스가 docker-compose.prod.yml에 정의되어 있지 않습니다." | tee -a $DEPLOY_LOG
              fi
            done
          else
            echo "인프라 서비스 배포 중..." | tee -a $DEPLOY_LOG
            # 기본 인프라 서비스만 시작
            docker-compose -f docker-compose.prod.yml up -d postgres mongodb redis zookeeper kafka kafka-ui kong static-web node-exporter kibana logstash mongodb-exporter postgres-exporter redis-exporter elasticsearch-exporter kong-blackbox-exporter kibana-blackbox-exporter mongodb-blackbox-exporter
            
            echo "애플리케이션 서비스 배포 중..." | tee -a $DEPLOY_LOG
            # 각 서비스 개별 시작 (오류 격리)
            for service in auth-service realtime-service session-service feedback-service user-service report-service; do
              if ! echo "$MISSING_IMAGES" | grep -q "$service"; then
                echo "서비스 시작: $service" | tee -a $DEPLOY_LOG
                docker-compose -f docker-compose.prod.yml up -d $service || echo "경고: $service 시작 실패" | tee -a $DEPLOY_LOG
              else
                echo "건너뛰기: $service (이미지 누락)" | tee -a $DEPLOY_LOG
              fi
            done
          fi
          
          # 배포 완료 확인
          echo "컨테이너 상태:" | tee -a $DEPLOY_LOG
          docker-compose -f docker-compose.prod.yml ps | tee -a $DEPLOY_LOG
          
          # 실행 중인 컨테이너 수 확인
          RUNNING_COUNT=$(docker-compose -f docker-compose.prod.yml ps --services --filter "status=running" | wc -l)
          echo "실행 중인 컨테이너 수: $RUNNING_COUNT" | tee -a $DEPLOY_LOG
          
          # 헬스 체크
          echo "헬스 체크 수행 중..." | tee -a $DEPLOY_LOG
          sleep 10
          
          # 주요 서비스 헬스 체크
          for service in postgres redis kong; do
            if docker-compose -f docker-compose.prod.yml ps $service | grep -q "Up"; then
              echo "$service: 정상 실행 중" | tee -a $DEPLOY_LOG
            else
              echo "$service: 실행 중이 아님" | tee -a $DEPLOY_LOG
            fi
          done
          
          echo "===== 배포 완료: $(date) =====" | tee -a $DEPLOY_LOG
          DEPLOY_EOF
          
          chmod +x deploy.sh
          scp -o StrictHostKeyChecking=no deploy.sh raspberry-pi:/home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/
          
          # 롤백 스크립트 생성
          cat > rollback.sh << 'ROLLBACK_EOF'
          #!/bin/bash
          set -e
          
          echo "===== 롤백 시작: $(date) ====="
          cd /home/${USER}/haptitalk
          
          # 현재 상태 저장
          docker-compose -f docker-compose.prod.yml ps > container_state_before_rollback.txt || true
          
          # 컨테이너 중지
          echo "컨테이너 중지 중..."
          docker-compose -f docker-compose.prod.yml down --remove-orphans
          
          # 이전 이미지 태그로 롤백 (develop -> latest, latest -> previous)
          if [ -f ".env.backup" ]; then
            echo "이전 환경 설정으로 복원 중..."
            cp .env.backup .env
          fi
          
          # 서비스 재시작
          echo "서비스 재시작 중..."
          docker-compose -f docker-compose.prod.yml up -d
          
          echo "===== 롤백 완료: $(date) ====="
          docker-compose -f docker-compose.prod.yml ps
          ROLLBACK_EOF
          
          chmod +x rollback.sh
          scp -o StrictHostKeyChecking=no rollback.sh raspberry-pi:/home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/

      - name: Deploy Services
        id: deploy
        run: |
          # 배포 실행
          SPECIFIC_SERVICES="${{ needs.prepare_deployment.outputs.specific_services }}"
          FORCE_RESTART="${{ needs.prepare_deployment.outputs.force_restart }}"
          IMAGES_AVAILABLE="${{ needs.validate_images.outputs.images_available }}"
          MISSING_IMAGES="${{ needs.validate_images.outputs.missing_images }}"
          BUILD_REQUIRED="${{ needs.validate_images.outputs.build_required }}"
          
          echo "배포 시작: 환경=${{ needs.prepare_deployment.outputs.environment }}"
          echo "특정 서비스: $SPECIFIC_SERVICES"
          echo "강제 재시작: $FORCE_RESTART"
          echo "이미지 사용 가능: $IMAGES_AVAILABLE"
          echo "누락된 이미지: $MISSING_IMAGES"
          echo "빌드 필요: $BUILD_REQUIRED"
          
          # 라즈베리파이에서 배포 실행
          ssh raspberry-pi "
            cd /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk
            
            # 환경 변수 백업 (롤백용)
            cp .env .env.backup || echo '기존 .env 파일이 없습니다.'
            
            # 환경 변수 파일에 GitHub Container Registry 설정 추가
            echo 'GITHUB_REPOSITORY_OWNER=$(echo "${{ github.repository_owner }}" | tr "[:upper:]" "[:lower:]")' >> .env
            echo 'IMAGE_TAG=${{ needs.prepare_deployment.outputs.image_tag }}' >> .env
            echo 'KONG_IMAGE=${{ needs.prepare_deployment.outputs.kong_image }}' >> .env
            echo 'DEPLOY_TIMESTAMP=$(date +%Y%m%d_%H%M%S)' >> .env
            echo 'DEPLOY_BRANCH=${{ github.ref_name }}' >> .env
            echo 'DEPLOY_COMMIT=${{ github.sha }}' >> .env
            
            # GitHub Container Registry 인증
            echo '${{ secrets.GHCR_PAT }}' | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
            
            echo '=== ARM64 호환 배포 시작 ==='
            
            # 기존 컨테이너 정리
            echo '=== 기존 컨테이너 정리 중 ==='
            docker-compose -f docker-compose.prod.yml down --remove-orphans || echo '기존 컨테이너 정리 완료'
            
            # 환경 변수 확인
            echo '=== 환경 변수 확인 ==='
            echo \"POSTGRES_USER: \${POSTGRES_USER:+설정됨}\"
            echo \"REDIS_PASSWORD: \${REDIS_PASSWORD:+설정됨}\"
            echo \"MONGO_USER: \${MONGO_USER:+설정됨}\"
            
            # 네트워크 생성
            echo '=== Docker 네트워크 확인/생성 ==='
            docker network create haptitalk_network 2>/dev/null || echo 'haptitalk_network 이미 존재'
            
            # 1단계: 핵심 데이터베이스 서비스 시작
            echo '=== 1단계: 핵심 데이터베이스 서비스 시작 ==='
            docker-compose -f docker-compose.prod.yml up -d postgres mongodb redis
            
            echo '=== 데이터베이스 서비스 준비 대기 (30초) ==='
            sleep 30
            
            # 데이터베이스 상태 확인
            echo '=== 데이터베이스 상태 확인 ==='
            docker-compose -f docker-compose.prod.yml ps postgres mongodb redis
            
            # 2단계: 메시징 시스템 시작
            echo '=== 2단계: 메시징 시스템 시작 ==='
            docker-compose -f docker-compose.prod.yml up -d zookeeper
            sleep 10
            docker-compose -f docker-compose.prod.yml up -d kafka
            sleep 15
            docker-compose -f docker-compose.prod.yml up -d kafka-ui
            
            # 3단계: API 게이트웨이 및 정적 웹 서버 시작
            echo '=== 3단계: API 게이트웨이 및 웹 서버 시작 ==='
            docker-compose -f docker-compose.prod.yml up -d kong static-web
            
            # 4단계: 모니터링 시스템 시작
            echo '=== 4단계: 모니터링 시스템 시작 ==='
            docker-compose -f docker-compose.prod.yml up -d elasticsearch
            sleep 20
            docker-compose -f docker-compose.prod.yml up -d kibana logstash filebeat
            sleep 15
            docker-compose -f docker-compose.prod.yml up -d jaeger otel-collector
            sleep 10
            docker-compose -f docker-compose.prod.yml up -d prometheus grafana node-exporter
            
            # 5단계: Exporters 시작
            echo '=== 5단계: Exporters 시작 ==='
            docker-compose -f docker-compose.prod.yml up -d mongodb-exporter postgres-exporter redis-exporter elasticsearch-exporter
            
            # 6단계: Blackbox Exporters 시작
            echo '=== 6단계: Blackbox Exporters 시작 ==='
            docker-compose -f docker-compose.prod.yml up -d kong-blackbox-exporter kibana-blackbox-exporter mongodb-blackbox-exporter
            
            # 중간 상태 확인
            echo '=== 중간 상태 확인 ==='
            docker-compose -f docker-compose.prod.yml ps
            
            # 7단계: 애플리케이션 서비스 시작
            echo '=== 7단계: 애플리케이션 서비스 시작 ==='
            
            # 이미지가 사용 가능한 서비스만 배포
            if [[ '$IMAGES_AVAILABLE' == 'true' ]]; then
              echo '모든 이미지가 사용 가능합니다. 전체 서비스를 시작합니다.'
              
              # 개별적으로 시작 (실패 시에도 계속 진행)
              for service in auth-service session-service user-service feedback-service report-service realtime-service; do
                echo \"서비스 시작: \$service\"
                docker-compose -f docker-compose.prod.yml up -d \$service || echo \"경고: \$service 시작 실패\"
                sleep 5
              done
            else
              echo '일부 이미지가 누락되었습니다. 사용 가능한 서비스만 시작합니다.'
              
              # 개별 서비스 시작 (오류 무시)
              for service in auth-service session-service user-service feedback-service report-service realtime-service; do
                if ! echo '$MISSING_IMAGES' | grep -q \"\$service\"; then
                  echo \"서비스 시작: \$service\"
                  docker-compose -f docker-compose.prod.yml up -d \$service || echo \"경고: \$service 시작 실패\"
                  sleep 5
                else
                  echo \"건너뛰기: \$service (이미지 누락)\"
                fi
              done
            fi
            
            # 최종 상태 확인
            echo '=== 최종 배포 상태 ==='
            docker-compose -f docker-compose.prod.yml ps
            
            # 실행 중인 컨테이너 수 확인
            RUNNING_CONTAINERS=\$(docker-compose -f docker-compose.prod.yml ps | grep -c \"Up\")
            echo \"실행 중인 컨테이너 수: \$RUNNING_CONTAINERS\"
            
            # 배포 후 정리 작업
            echo '=== 배포 후 정리 ==='
            docker system prune -f || echo '시스템 정리 완료'
            
            echo '=== 배포 완료 ==='
          "
      
      - name: Get Current Time
        id: current_time
        run: echo "time=$(date +'%Y-%m-%d %H:%M:%S')" >> $GITHUB_OUTPUT
      
      - name: Verify Deployment
        id: verify
        run: |
          # 배포 검증 (디버깅 강화)
          VERIFICATION=$(ssh raspberry-pi '
            cd /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk
            
            echo "===== 디버깅 정보 시작 ====="
            echo "현재 디렉토리: $(pwd)"
            echo "현재 시간: $(date)"
            echo "사용자: $(whoami)"
            
            # 환경 변수 파일 확인
            echo "===== 환경 변수 파일 확인 ====="
            if [ -f ".env" ]; then
              echo ".env 파일 존재 - 크기: $(stat -c%s .env) bytes"
              echo "주요 환경 변수 확인:"
              grep -E "^(POSTGRES_|REDIS_|MONGO_)" .env | head -5 | sed "s/=.*$/=***/"
            else
              echo "❌ .env 파일이 없습니다!"
            fi
            
            # Docker 상태 확인
            echo "===== Docker 상태 확인 ====="
            echo "Docker 버전: $(docker --version)"
            echo "Docker Compose 버전: $(docker-compose --version)"
            echo "Docker 데몬 상태: $(docker info > /dev/null 2>&1 && echo "정상" || echo "오류")"
            
            # Docker Compose 파일 확인
            echo "===== Docker Compose 파일 확인 ====="
            if [ -f "docker-compose.prod.yml" ]; then
              echo "docker-compose.prod.yml 파일 존재 - 크기: $(stat -c%s docker-compose.prod.yml) bytes"
              echo "첫 번째 서비스:"
              head -20 docker-compose.prod.yml | grep -A 5 "services:"
            else
              echo "❌ docker-compose.prod.yml 파일이 없습니다!"
            fi
            
            # 환경 변수 로드 시도
            echo "===== 환경 변수 로드 시도 ====="
            if [ -f ".env" ]; then
              source .env
              echo "POSTGRES_USER 로드됨: ${POSTGRES_USER:+설정됨}"
              echo "REDIS_PASSWORD 로드됨: ${REDIS_PASSWORD:+설정됨}"
              echo "MONGO_USER 로드됨: ${MONGO_USER:+설정됨}"
            fi
            
            # Docker 네트워크 확인
            echo "===== Docker 네트워크 확인 ====="
            docker network ls | grep haptitalk || echo "haptitalk 네트워크 없음"
            
            # 실행 중인 컨테이너 확인
            echo "===== 실행 중인 컨테이너 ====="
            docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
            
            # 모든 컨테이너 확인 (중지된 것 포함)
            echo "===== 모든 컨테이너 (중지된 것 포함) ====="
            docker ps -a --format "table {{.Names}}\t{{.Status}}\t{{.Image}}" | head -20
            
            # Docker Compose 서비스 상태
            echo "===== Docker Compose 서비스 상태 ====="
            if [ -f "docker-compose.prod.yml" ]; then
              docker-compose -f docker-compose.prod.yml ps
            else
              echo "docker-compose.prod.yml 파일 없음"
            fi
            
            # Docker 로그 확인 (간단히)
            echo "===== Docker 시스템 이벤트 (최근 10개) ====="
            docker system events --since="10m" --until="now" | tail -10 || echo "이벤트 없음"
            
            # 디스크 공간 확인
            echo "===== 시스템 리소스 ====="
            echo "디스크 사용률:"
            df -h / | grep -v "Filesystem"
            echo "메모리 사용률:"
            free -h | grep -E "Mem:|Swap:"
            
            # 간단한 헬스체크 (docker-compose 기반으로 수정)
            echo "===== 간단한 헬스체크 ====="
            
            # Docker Compose 서비스 상태 직접 확인
            COMPOSE_PS_OUTPUT=$(docker-compose -f docker-compose.prod.yml ps)
            echo "Docker Compose 서비스 상태:"
            echo "$COMPOSE_PS_OUTPUT"
            
            # PostgreSQL 확인
            if echo "$COMPOSE_PS_OUTPUT" | grep -q "postgres.*Up"; then
              echo "PostgreSQL 컨테이너: 실행 중"
              POSTGRES_HEALTH=$(docker-compose -f docker-compose.prod.yml exec -T postgres pg_isready 2>/dev/null && echo "OK" || echo "FAIL")
              echo "PostgreSQL 헬스체크: $POSTGRES_HEALTH"
            else
              echo "PostgreSQL 컨테이너: 실행 중이 아님"
              echo "PostgreSQL: FAIL"
            fi
            
            # Redis 확인
            if echo "$COMPOSE_PS_OUTPUT" | grep -q "redis.*Up"; then
              echo "Redis 컨테이너: 실행 중"
              REDIS_HEALTH=$(docker-compose -f docker-compose.prod.yml exec -T redis redis-cli ping 2>/dev/null && echo "OK" || echo "FAIL")
              echo "Redis 헬스체크: $REDIS_HEALTH"
            else
              echo "Redis 컨테이너: 실행 중이 아님"
              echo "Redis: FAIL"
            fi
            
            # Kong 확인
            if echo "$COMPOSE_PS_OUTPUT" | grep -q "kong.*Up"; then
              echo "Kong 컨테이너: 실행 중"
              KONG_HEALTH=$(docker-compose -f docker-compose.prod.yml exec -T kong kong version 2>/dev/null && echo "OK" || echo "FAIL")
              echo "Kong 헬스체크: $KONG_HEALTH"
            else
              echo "Kong 컨테이너: 실행 중이 아님"
              echo "Kong: FAIL"
            fi
            
            # MongoDB 확인
            if echo "$COMPOSE_PS_OUTPUT" | grep -q "mongodb.*Up"; then
              echo "MongoDB 컨테이너: 실행 중"
              MONGODB_HEALTH=$(docker-compose -f docker-compose.prod.yml exec -T mongodb mongosh --quiet --eval "db.runCommand({ping: 1}).ok" 2>/dev/null | grep -q "1" && echo "OK" || echo "FAIL")
              echo "MongoDB 헬스체크: $MONGODB_HEALTH"
            else
              echo "MongoDB 컨테이너: 실행 중이 아님"
              echo "MongoDB: FAIL"
            fi
            
            # Kafka 확인
            if echo "$COMPOSE_PS_OUTPUT" | grep -q "kafka.*Up"; then
              echo "Kafka 컨테이너: 실행 중"
              KAFKA_HEALTH=$(docker-compose -f docker-compose.prod.yml exec -T kafka kafka-topics.sh --bootstrap-server localhost:9092 --list 2>/dev/null >/dev/null && echo "OK" || echo "FAIL")
              echo "Kafka 헬스체크: $KAFKA_HEALTH"
            else
              echo "Kafka 컨테이너: 실행 중이 아님"
              echo "Kafka: FAIL"
            fi
            
            # 애플리케이션 서비스 상태 확인
            echo "===== 애플리케이션 서비스 상태 ====="
            for service in auth-service session-service user-service feedback-service report-service realtime-service; do
              if echo "$COMPOSE_PS_OUTPUT" | grep -q "$service.*Up"; then
                # 헬스체크 상태도 확인
                if echo "$COMPOSE_PS_OUTPUT" | grep "$service" | grep -q "healthy"; then
                  echo "$service: OK (healthy)"
                else
                  echo "$service: OK (running)"
                fi
              else
                echo "$service: FAIL"
              fi
            done
            
            echo "===== 디버깅 정보 끝 ====="
          ')
          
          echo "$VERIFICATION"
          
          # 핵심 서비스 실행 여부 확인 (docker-compose 기반으로 수정)
          CORE_SERVICES_RUNNING=0
          
          # 각 핵심 서비스가 실행 중인지 확인
          if echo "$VERIFICATION" | grep -q "PostgreSQL 컨테이너: 실행 중"; then
            CORE_SERVICES_RUNNING=$((CORE_SERVICES_RUNNING + 1))
          fi
          
          if echo "$VERIFICATION" | grep -q "Redis 컨테이너: 실행 중"; then
            CORE_SERVICES_RUNNING=$((CORE_SERVICES_RUNNING + 1))
          fi
          
          if echo "$VERIFICATION" | grep -q "MongoDB 컨테이너: 실행 중"; then
            CORE_SERVICES_RUNNING=$((CORE_SERVICES_RUNNING + 1))
          fi
          
          if echo "$VERIFICATION" | grep -q "Kafka 컨테이너: 실행 중"; then
            CORE_SERVICES_RUNNING=$((CORE_SERVICES_RUNNING + 1))
          fi
          
          # Kong은 unhealthy 상태여도 실행 중이면 OK로 간주
          if echo "$VERIFICATION" | grep -q "Kong 컨테이너: 실행 중"; then
            CORE_SERVICES_RUNNING=$((CORE_SERVICES_RUNNING + 1))
          fi
          
          # 애플리케이션 서비스 실행 여부 확인 (OK 패턴으로 수정)
          APP_SERVICES_RUNNING=$(echo "$VERIFICATION" | grep -c ": OK (healthy)\|: OK (running)")
          
          echo "핵심 서비스 실행 중: $CORE_SERVICES_RUNNING/5"
          echo "애플리케이션 서비스 실행 중: $APP_SERVICES_RUNNING"
          
          # 성공 조건: 핵심 서비스 4개 이상 + 애플리케이션 서비스 3개 이상
          if [ "$CORE_SERVICES_RUNNING" -ge 4 ] && [ "$APP_SERVICES_RUNNING" -ge 3 ]; then
            echo "deploy_success=true" >> $GITHUB_OUTPUT
            echo "verification_result=배포 성공! 핵심 서비스 $CORE_SERVICES_RUNNING/5개, 앱 서비스 $APP_SERVICES_RUNNING개 실행 중" >> $GITHUB_OUTPUT
          else
            echo "deploy_success=false" >> $GITHUB_OUTPUT
            echo "verification_result=배포 실패. 핵심 서비스 $CORE_SERVICES_RUNNING/5개, 앱 서비스 $APP_SERVICES_RUNNING개만 실행 중" >> $GITHUB_OUTPUT
          fi
      
      - name: Rollback if Necessary
        id: rollback
        if: steps.verify.outputs.deploy_success == 'false'
        run: |
          echo "배포 검증 실패, 롤백을 진행합니다..."
          
          ROLLBACK_RESULT=$(ssh raspberry-pi '
            cd /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk
            
            # 환경 변수 로드
            source .env
            
            echo "===== 롤백 시작 ====="
            echo "롤백 시작 시간: $(date)"
            
            # 현재 상태 백업
            echo "현재 컨테이너 상태 백업..."
            docker-compose -f docker-compose.prod.yml ps > rollback_before_state.log
            
            # 모든 서비스 정지 (graceful shutdown)
            echo "서비스 정지 중..."
            docker-compose -f docker-compose.prod.yml stop
            
            # 컨테이너 제거 (orphan 컨테이너 포함)
            echo "컨테이너 정리 중..."
            docker-compose -f docker-compose.prod.yml down --remove-orphans --volumes
            
            # 최신 이미지 pull (롤백을 위해)
            echo "최신 이미지 확인 중..."
            docker-compose -f docker-compose.prod.yml pull --ignore-pull-failures
            
            # 이전 환경 설정 복원 (있는 경우)
            if [ -f ".env.backup" ]; then
              echo "이전 환경 설정 복원 중..."
              cp .env.backup .env
            fi
            
            # 핵심 인프라 서비스부터 단계적으로 시작
            echo "핵심 인프라 서비스 시작 중..."
            docker-compose -f docker-compose.prod.yml up -d postgres mongodb redis zookeeper
            sleep 10
            
            echo "메시징 및 API 게이트웨이 시작 중..."
            docker-compose -f docker-compose.prod.yml up -d kafka kong
            sleep 10
            
            echo "모니터링 서비스 시작 중..."
            docker-compose -f docker-compose.prod.yml up -d prometheus grafana elasticsearch kibana
            sleep 15
            
            # 롤백 후 상태 확인
            echo "===== 롤백 후 상태 확인 ====="
            docker-compose -f docker-compose.prod.yml ps
            
            # 기본 헬스체크
            echo "===== 롤백 후 헬스체크 ====="
            
            # PostgreSQL 체크
            POSTGRES_CHECK=$(docker-compose -f docker-compose.prod.yml exec -T postgres pg_isready -U "$POSTGRES_USER" -d "$POSTGRES_DB" 2>/dev/null && echo "OK" || echo "FAIL")
            echo "PostgreSQL: $POSTGRES_CHECK"
            
            # Redis 체크
            REDIS_CHECK=$(docker-compose -f docker-compose.prod.yml exec -T redis redis-cli -a "$REDIS_PASSWORD" ping 2>/dev/null && echo "OK" || echo "FAIL")
            echo "Redis: $REDIS_CHECK"
            
            # MongoDB 체크
            MONGODB_CHECK=$(docker-compose -f docker-compose.prod.yml exec -T mongodb mongosh --quiet --eval "db.runCommand({ping: 1}).ok" 2>/dev/null | grep -q "1" && echo "OK" || echo "FAIL")
            echo "MongoDB: $MONGODB_CHECK"
            
            # 롤백 완료 시간
            echo "===== 롤백 완료: $(date) ====="
            
            # 롤백 성공 여부 판단
            if [[ "$POSTGRES_CHECK" == "OK" && "$REDIS_CHECK" == "OK" && "$MONGODB_CHECK" == "OK" ]]; then
              echo "ROLLBACK_SUCCESS=true"
            else
              echo "ROLLBACK_SUCCESS=false"
            fi
          ')
          
          echo "$ROLLBACK_RESULT"
          
          # 롤백 결과 확인
          if echo "$ROLLBACK_RESULT" | grep -q "ROLLBACK_SUCCESS=true"; then
            echo "✅ 롤백이 성공적으로 완료되었습니다."
            echo "rollback_success=true" >> $GITHUB_OUTPUT
          else
            echo "❌ 롤백 중 문제가 발생했습니다. 수동 개입이 필요합니다."
            echo "rollback_success=false" >> $GITHUB_OUTPUT
            exit 1
          fi
      
      - name: Send Deployment Notification
        if: always()
        uses: rtCamp/action-slack-notify@v2
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
          SLACK_CHANNEL: ${{ secrets.SLACK_CHANNEL || 'deployments' }}
          SLACK_COLOR: ${{ (steps.verify.outputs.deploy_success == 'false' && 'danger') || job.status }}
          SLACK_TITLE: Raspberry Pi Deployment - ${{ needs.prepare_deployment.outputs.environment }}
          SLACK_MESSAGE: |
            *🚀 라즈베리파이 ARM64 배포 결과*
            
            *환경:* ${{ needs.prepare_deployment.outputs.environment }}
            *상태:* ${{ steps.verify.outputs.deploy_success == 'false' && (steps.rollback.outputs.rollback_success == 'true' && '⚠️ 배포 실패 (롤백 완료)' || '🚨 배포 및 롤백 실패') || '✅ 배포 성공' }}
            *플랫폼:* ${{ needs.prepare_deployment.outputs.platform_arch }}
            *Kong 이미지:* ${{ needs.prepare_deployment.outputs.kong_image }}
            
            *배포 서비스:* ${{ needs.prepare_deployment.outputs.specific_services || '전체 서비스' }}
            *강제 재시작:* ${{ needs.prepare_deployment.outputs.force_restart }}
            *이미지 상태:* ${{ needs.validate_images.outputs.images_available == 'true' && '✅ 모든 이미지 사용 가능' || '⚠️ 일부 이미지 누락' }}
            ${{ needs.validate_images.outputs.missing_images && format('*누락된 이미지:* {0}', needs.validate_images.outputs.missing_images) || '' }}
            
            *검증 결과:* ${{ steps.verify.outputs.verification_result || '검증 정보 없음' }}
            ${{ steps.verify.outputs.deploy_success == 'false' && format('*롤백 상태:* {0}', (steps.rollback.outputs.rollback_success == 'true' && '✅ 롤백 성공' || '❌ 롤백 실패 - 수동 개입 필요')) || '' }}
            
            *시스템 리소스:*
            • 디스크 공간: ${{ steps.disk_check.outputs.disk_usage }}% 사용 (가용: ${{ steps.disk_check.outputs.available_space }})
            • 메모리: 가용 ${{ steps.ram_check.outputs.available_ram }}
            
            *배포 정보:*
            • 브랜치: ${{ github.ref_name }}
            • 커밋: ${{ github.sha }}
            • 배포 시간: ${{ steps.current_time.outputs.time }}
            • 워크플로우: <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|상세 보기>
            
            ${{ steps.verify.outputs.deploy_success == 'true' && '*📊 모니터링 대시보드:*
            • Grafana: http://${{ secrets.RASPBERRY_PI_IP }}:3000
            • Prometheus: http://${{ secrets.RASPBERRY_PI_IP }}:9090
            • Kibana: http://${{ secrets.RASPBERRY_PI_IP }}:5601
            • Jaeger: http://${{ secrets.RASPBERRY_PI_IP }}:16686
            • Elasticsearch: http://${{ secrets.RASPBERRY_PI_IP }}:9200
            
            *🔧 시스템 메트릭:*
            • Node Exporter: http://${{ secrets.RASPBERRY_PI_IP }}:9100/metrics
            • MongoDB Exporter: http://${{ secrets.RASPBERRY_PI_IP }}:9216/metrics
            • PostgreSQL Exporter: http://${{ secrets.RASPBERRY_PI_IP }}:9187/metrics
            • Redis Exporter: http://${{ secrets.RASPBERRY_PI_IP }}:9121/metrics
            • Elasticsearch Exporter: http://${{ secrets.RASPBERRY_PI_IP }}:9114/metrics
            • Logstash API: http://${{ secrets.RASPBERRY_PI_IP }}:9600' || '' }}
            
            ${{ steps.verify.outputs.deploy_success == 'false' && '*⚠️ 문제 해결이 필요합니다:*
            • 라즈베리파이 SSH 접속: `ssh ${{ secrets.RASPBERRY_PI_USER }}@${{ secrets.RASPBERRY_PI_IP }}`
            • 로그 확인: `cd /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk && docker-compose -f docker-compose.prod.yml logs --tail=100`
            • 수동 재시작: `docker-compose -f docker-compose.prod.yml restart`' || '' }}
          SLACK_FOOTER: 'HaptiTalk CI/CD - ARM64 Deployment Pipeline'
        continue-on-error: true

      - name: Setup Monitoring
        if: steps.verify.outputs.deploy_success == 'true'
        run: |
          echo "배포 성공 후 모니터링 설정 중..."
          
          ssh raspberry-pi "
            cd /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk
            
            # 모니터링 스크립트 생성
            cat > monitor.sh << 'MONITOR_EOF'
          #!/bin/bash
          
          # 서비스 상태 모니터링
          echo '===== 서비스 상태 모니터링 ====='
          echo \"모니터링 시간: \$(date)\"
          
          # Docker 컨테이너 상태
          echo '--- Docker 컨테이너 상태 ---'
          docker-compose -f docker-compose.prod.yml ps
          
          # 시스템 리소스
          echo '--- 시스템 리소스 ---'
          echo \"CPU 사용률: \$(top -bn1 | grep 'Cpu(s)' | awk '{print \$2}' | cut -d'%' -f1)%\"
          echo \"메모리 사용률: \$(free | grep Mem | awk '{printf \"%.1f%%\", \$3/\$2 * 100.0}')\"
          echo \"디스크 사용률: \$(df -h / | awk 'NR==2{print \$5}')\"
          
          # 네트워크 연결 확인
          echo '--- 네트워크 연결 확인 ---'
          if curl -s http://localhost:8000 > /dev/null; then
            echo 'Kong API Gateway: 정상'
          else
            echo 'Kong API Gateway: 오류'
          fi
          
          # 로그 확인 (최근 오류)
          echo '--- 최근 오류 로그 ---'
          docker-compose -f docker-compose.prod.yml logs --tail=10 | grep -i 'error\|exception\|fatal' || echo '최근 오류 없음'
          
          echo '============================='
          MONITOR_EOF
          
          chmod +x monitor.sh
          
          # 모니터링 크론잡 설정 (5분마다 실행)
          (crontab -l 2>/dev/null; echo '*/5 * * * * /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/monitor.sh >> /home/${{ secrets.RASPBERRY_PI_USER }}/haptitalk/logs/monitor.log 2>&1') | crontab -
          
          echo '모니터링 설정 완료'
          "
      
      - name: Create Deployment Summary
        if: always()
        run: |
          echo "## 🚀 라즈베리파이 ARM64 배포 요약" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📋 배포 정보" >> $GITHUB_STEP_SUMMARY
          echo "- **환경**: ${{ needs.prepare_deployment.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "- **플랫폼**: ${{ needs.prepare_deployment.outputs.platform_arch }}" >> $GITHUB_STEP_SUMMARY
          echo "- **이미지 태그**: ${{ needs.prepare_deployment.outputs.image_tag }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Kong 이미지**: ${{ needs.prepare_deployment.outputs.kong_image }}" >> $GITHUB_STEP_SUMMARY
          echo "- **배포 시간**: ${{ steps.current_time.outputs.time }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### 🖼️ 이미지 상태" >> $GITHUB_STEP_SUMMARY
          if [[ "${{ needs.validate_images.outputs.images_available }}" == "true" ]]; then
            echo "✅ **모든 이미지 사용 가능**" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ **일부 이미지 누락**" >> $GITHUB_STEP_SUMMARY
            echo "- 누락된 이미지: ${{ needs.validate_images.outputs.missing_images }}" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### 💾 시스템 리소스" >> $GITHUB_STEP_SUMMARY
          echo "- **디스크 사용률**: ${{ steps.disk_check.outputs.disk_usage }}%" >> $GITHUB_STEP_SUMMARY
          echo "- **사용 가능한 디스크 공간**: ${{ steps.disk_check.outputs.available_space }}" >> $GITHUB_STEP_SUMMARY
          echo "- **사용 가능한 메모리**: ${{ steps.ram_check.outputs.available_ram }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### 🎯 배포 결과" >> $GITHUB_STEP_SUMMARY
          if [[ "${{ steps.verify.outputs.deploy_success }}" == "true" ]]; then
            echo "✅ **배포 성공**" >> $GITHUB_STEP_SUMMARY
            echo "- ${{ steps.verify.outputs.verification_result }}" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **배포 실패**" >> $GITHUB_STEP_SUMMARY
            echo "- ${{ steps.verify.outputs.verification_result }}" >> $GITHUB_STEP_SUMMARY
            echo "- 롤백이 자동으로 수행되었습니다." >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### 🔗 유용한 링크" >> $GITHUB_STEP_SUMMARY
          echo "- [Kong Admin API](http://${{ secrets.RASPBERRY_PI_IP }}:8001)" >> $GITHUB_STEP_SUMMARY
          echo "- [Kafka UI](http://${{ secrets.RASPBERRY_PI_IP }}:8080)" >> $GITHUB_STEP_SUMMARY
          echo "- [API Gateway](http://${{ secrets.RASPBERRY_PI_IP }}:8000)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📊 모니터링 대시보드" >> $GITHUB_STEP_SUMMARY
          echo "- [Grafana](http://${{ secrets.RASPBERRY_PI_IP }}:3000) - 통합 모니터링 대시보드" >> $GITHUB_STEP_SUMMARY
          echo "- [Prometheus](http://${{ secrets.RASPBERRY_PI_IP }}:9090) - 메트릭 수집" >> $GITHUB_STEP_SUMMARY
          echo "- [Kibana](http://${{ secrets.RASPBERRY_PI_IP }}:5601) - 로그 분석" >> $GITHUB_STEP_SUMMARY
          echo "- [Jaeger](http://${{ secrets.RASPBERRY_PI_IP }}:16686) - 분산 트레이싱" >> $GITHUB_STEP_SUMMARY
          echo "- [Elasticsearch](http://${{ secrets.RASPBERRY_PI_IP }}:9200) - 로그 저장소" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🔧 시스템 메트릭" >> $GITHUB_STEP_SUMMARY
          echo "- [Node Exporter](http://${{ secrets.RASPBERRY_PI_IP }}:9100/metrics) - 시스템 메트릭" >> $GITHUB_STEP_SUMMARY
          echo "- [MongoDB Exporter](http://${{ secrets.RASPBERRY_PI_IP }}:9216/metrics) - MongoDB 메트릭" >> $GITHUB_STEP_SUMMARY
          echo "- [PostgreSQL Exporter](http://${{ secrets.RASPBERRY_PI_IP }}:9187/metrics) - PostgreSQL 메트릭" >> $GITHUB_STEP_SUMMARY
          echo "- [Redis Exporter](http://${{ secrets.RASPBERRY_PI_IP }}:9121/metrics) - Redis 메트릭" >> $GITHUB_STEP_SUMMARY
          echo "- [Elasticsearch Exporter](http://${{ secrets.RASPBERRY_PI_IP }}:9114/metrics) - Elasticsearch 메트릭" >> $GITHUB_STEP_SUMMARY
          echo "- [Logstash API](http://${{ secrets.RASPBERRY_PI_IP }}:9600) - Logstash 상태" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🔍 상태 모니터링" >> $GITHUB_STEP_SUMMARY
          echo "- [Kong Blackbox](http://${{ secrets.RASPBERRY_PI_IP }}:9701) - Kong 상태 확인" >> $GITHUB_STEP_SUMMARY
          echo "- [Kibana Blackbox](http://${{ secrets.RASPBERRY_PI_IP }}:9702) - Kibana 상태 확인" >> $GITHUB_STEP_SUMMARY
          echo "- [MongoDB Blackbox](http://${{ secrets.RASPBERRY_PI_IP }}:9703) - MongoDB 상태 확인" >> $GITHUB_STEP_SUMMARY
